{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "745310cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import optuna\n",
    "import yfinance as yf\n",
    "import pandas_datareader.data as web\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas_ta as ta\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Nadam\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9f252f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category = pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bdd371a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Pobieramy dane dotyczące BTC z yahoo\n",
    "BTC = yf.download('BTC-USD', start = '2018-01-01', end = '2019-12-31')\n",
    "\n",
    "BTC['Target'] = (BTC['Close'].diff() > 0).astype(int)\n",
    "\n",
    "def add_lagged_features(data, column_name, n_days):\n",
    "    for i in range(1, n_days + 1):\n",
    "        lagged_column_name = f'{column_name}_{i}d_back'\n",
    "        data[lagged_column_name] = data[column_name].shift(i)\n",
    "    return data\n",
    "\n",
    "BTC = add_lagged_features(BTC, 'Close', 30)\n",
    "BTC = add_lagged_features(BTC, 'Volume', 30)\n",
    "\n",
    "# Usuwamy pierwszych 30 wierszy\n",
    "BTC = BTC.dropna().reset_index(drop = True)\n",
    "\n",
    "# print(BTC.head())\n",
    "# print(len(BTC))\n",
    "# print(BTC.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e21a7637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konwersacja zmiennej Target na zmienną binarną\n",
    "target = to_categorical(BTC['Target'].values)\n",
    "\n",
    "# Usuwamy niepotrzebne kolumny\n",
    "features = BTC.drop(['Target', 'Adj Close'], axis = 1).values \n",
    "\n",
    "# Dzielimy dane na treningowe i testowe\n",
    "split_idx = int(len(features) * 0.8)\n",
    "\n",
    "m = int(np.floor(0.8 * len(features)))\n",
    "train_features = features[:m]\n",
    "test_features = features[m:]\n",
    "train_target = target[:m]\n",
    "test_target = target[m:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27027acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "##################################################\n",
    "# WERSJA MAŁO SKOMPLIKOWANA\n",
    "##################################################\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ead2065",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\48798\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.4841 - loss: 994302720.0000 - val_accuracy: 0.5446 - val_loss: 667419520.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5454 - loss: 143705472.0000 - val_accuracy: 0.4196 - val_loss: 534271936.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5825 - loss: 131994824.0000 - val_accuracy: 0.4196 - val_loss: 882118272.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5908 - loss: 108288768.0000 - val_accuracy: 0.4464 - val_loss: 244475216.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5430 - loss: 79586640.0000 - val_accuracy: 0.5536 - val_loss: 272233504.0000\n",
      "Epoch 6/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5746 - loss: 81269384.0000 - val_accuracy: 0.4196 - val_loss: 394203360.0000\n",
      "Epoch 7/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5190 - loss: 57098336.0000 - val_accuracy: 0.4286 - val_loss: 452313920.0000\n",
      "Epoch 8/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4739 - loss: 121557744.0000 - val_accuracy: 0.4286 - val_loss: 390940608.0000\n",
      "Epoch 9/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5531 - loss: 75051944.0000 - val_accuracy: 0.5179 - val_loss: 134100608.0000\n",
      "Epoch 10/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6092 - loss: 29415040.0000 - val_accuracy: 0.4464 - val_loss: 322038336.0000\n",
      "Epoch 11/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5639 - loss: 35651156.0000 - val_accuracy: 0.5982 - val_loss: 339183936.0000\n",
      "Epoch 12/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5238 - loss: 65495164.0000 - val_accuracy: 0.4554 - val_loss: 301195744.0000\n",
      "Epoch 13/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5190 - loss: 42920676.0000 - val_accuracy: 0.4375 - val_loss: 144670560.0000\n",
      "Epoch 14/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5432 - loss: 28031238.0000 - val_accuracy: 0.5982 - val_loss: 233059152.0000\n",
      "Epoch 15/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5041 - loss: 48675544.0000 - val_accuracy: 0.4554 - val_loss: 301032352.0000\n",
      "Epoch 16/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5541 - loss: 44682480.0000 - val_accuracy: 0.5714 - val_loss: 171471024.0000\n",
      "Epoch 17/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5650 - loss: 43416808.0000 - val_accuracy: 0.4375 - val_loss: 79915224.0000\n",
      "Epoch 18/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5340 - loss: 29409990.0000 - val_accuracy: 0.4732 - val_loss: 192077168.0000\n",
      "Epoch 19/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5816 - loss: 38906596.0000 - val_accuracy: 0.5893 - val_loss: 328918848.0000\n",
      "Epoch 20/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4796 - loss: 68152912.0000 - val_accuracy: 0.4911 - val_loss: 232270368.0000\n",
      "Epoch 21/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5128 - loss: 51114400.0000 - val_accuracy: 0.4643 - val_loss: 132049096.0000\n",
      "Epoch 22/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5811 - loss: 25652812.0000 - val_accuracy: 0.4464 - val_loss: 141533408.0000\n",
      "Epoch 23/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6172 - loss: 16324251.0000 - val_accuracy: 0.5893 - val_loss: 103444992.0000\n",
      "Epoch 24/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5817 - loss: 18306128.0000 - val_accuracy: 0.3929 - val_loss: 109767256.0000\n",
      "Epoch 25/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5997 - loss: 17858786.0000 - val_accuracy: 0.4375 - val_loss: 62163036.0000\n",
      "Epoch 26/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5862 - loss: 22118162.0000 - val_accuracy: 0.5357 - val_loss: 71020432.0000\n",
      "Epoch 27/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6275 - loss: 11411949.0000 - val_accuracy: 0.6071 - val_loss: 92949296.0000\n",
      "Epoch 28/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5612 - loss: 17343338.0000 - val_accuracy: 0.4196 - val_loss: 79078768.0000\n",
      "Epoch 29/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5923 - loss: 12690391.0000 - val_accuracy: 0.5625 - val_loss: 87898928.0000\n",
      "Epoch 30/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6080 - loss: 15294948.0000 - val_accuracy: 0.5982 - val_loss: 177528800.0000\n",
      "Epoch 31/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6192 - loss: 19086344.0000 - val_accuracy: 0.4554 - val_loss: 60274376.0000\n",
      "Epoch 32/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6043 - loss: 12986530.0000 - val_accuracy: 0.4375 - val_loss: 104424264.0000\n",
      "Epoch 33/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5703 - loss: 17292750.0000 - val_accuracy: 0.4018 - val_loss: 94613296.0000\n",
      "Epoch 34/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5729 - loss: 24796074.0000 - val_accuracy: 0.4196 - val_loss: 186396160.0000\n",
      "Epoch 35/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5490 - loss: 30791570.0000 - val_accuracy: 0.6071 - val_loss: 97861824.0000\n",
      "Epoch 36/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6253 - loss: 12097785.0000 - val_accuracy: 0.5804 - val_loss: 88825032.0000\n",
      "Epoch 37/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5928 - loss: 10680930.0000 - val_accuracy: 0.5536 - val_loss: 41761628.0000\n",
      "Epoch 38/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5885 - loss: 16191934.0000 - val_accuracy: 0.3839 - val_loss: 95741072.0000\n",
      "Epoch 39/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5941 - loss: 13555528.0000 - val_accuracy: 0.5357 - val_loss: 69218696.0000\n",
      "Epoch 40/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5533 - loss: 20093628.0000 - val_accuracy: 0.5893 - val_loss: 114796016.0000\n",
      "Epoch 41/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5819 - loss: 12692309.0000 - val_accuracy: 0.4286 - val_loss: 114254568.0000\n",
      "Epoch 42/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5313 - loss: 29917822.0000 - val_accuracy: 0.5179 - val_loss: 53551196.0000\n",
      "Epoch 43/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6316 - loss: 12079751.0000 - val_accuracy: 0.4286 - val_loss: 59148672.0000\n",
      "Epoch 44/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5232 - loss: 8967594.0000 - val_accuracy: 0.5536 - val_loss: 63153492.0000\n",
      "Epoch 45/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5526 - loss: 8698155.0000 - val_accuracy: 0.5714 - val_loss: 55768460.0000\n",
      "Epoch 46/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6011 - loss: 10969676.0000 - val_accuracy: 0.4464 - val_loss: 100592440.0000\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5088 - loss: 24917564.0000 - val_accuracy: 0.4643 - val_loss: 65960228.0000\n",
      "Epoch 48/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6624 - loss: 6815228.5000 - val_accuracy: 0.4554 - val_loss: 50190240.0000\n",
      "Epoch 49/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5835 - loss: 11129911.0000 - val_accuracy: 0.4018 - val_loss: 81501976.0000\n",
      "Epoch 50/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5898 - loss: 9339911.0000 - val_accuracy: 0.4643 - val_loss: 48453412.0000\n"
     ]
    }
   ],
   "source": [
    "# Budujemy model\n",
    "model = Sequential([\n",
    "    Dense(64, activation = 'relu', input_shape = (train_features.shape[1],)),\n",
    "    Dense(64, activation = 'relu'),\n",
    "    Dense(2, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Trenujemy model\n",
    "history = model.fit(train_features, train_target, epochs = 50, batch_size = 12, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a437042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "138\n",
      "189\n",
      "67\n",
      "165\n",
      "Accuracy (ACC): 0.5849731663685152\n",
      "True Positive Rate (TPR): 0.45544554455445546\n",
      "False Positive Rate (FPR): 0.26171875\n",
      "True Negative Rate (TNR): 0.73828125\n",
      "Positive Predictive Value (PPV): 0.6731707317073171\n",
      "Negative Predictive Value (NPV): 0.5338983050847458\n"
     ]
    }
   ],
   "source": [
    "# Predykcja na zbiorze treningowym\n",
    "train_predictions = model.predict(train_features)\n",
    "train_predictions = np.argmax(train_predictions, axis = 1)\n",
    "train_true = np.argmax(train_target, axis = 1)\n",
    "\n",
    "# Obliczanie macierzy pomyłek\n",
    "cm = confusion_matrix(train_true, train_predictions)\n",
    "TP = cm[1, 1]  # True Positives\n",
    "TN = cm[0, 0]  # True Negatives\n",
    "FP = cm[0, 1]  # False Positives\n",
    "FN = cm[1, 0]  # False Negatives\n",
    "\n",
    "print(TP)\n",
    "print(TN)\n",
    "print(FP)\n",
    "print(FN)\n",
    "\n",
    "# TPR, FPR, TNR, PPV, NPV\n",
    "ACC = (TP + TN) / (TP + TN + FP + FN)\n",
    "TPR = TP / (TP + FN)\n",
    "FPR = FP / (FP + TN)\n",
    "TNR = TN / (TN + FP)\n",
    "PPV = TP / (TP + FP)\n",
    "NPV = TN / (TN + FN)\n",
    "\n",
    "print('Accuracy (ACC):', ACC)\n",
    "print('True Positive Rate (TPR):', TPR)\n",
    "print('False Positive Rate (FPR):', FPR)\n",
    "print('True Negative Rate (TNR):', TNR)\n",
    "print('Positive Predictive Value (PPV):', PPV)\n",
    "print('Negative Predictive Value (NPV):', NPV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fa4bf70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "23\n",
      "54\n",
      "27\n",
      "36\n",
      "Accuracy (ACC): 0.55\n",
      "True Positive Rate (TPR): 0.3898305084745763\n",
      "False Positive Rate (FPR): 0.3333333333333333\n",
      "True Negative Rate (TNR): 0.6666666666666666\n",
      "Positive Predictive Value (PPV): 0.46\n",
      "Negative Predictive Value (NPV): 0.6\n"
     ]
    }
   ],
   "source": [
    "# Predykcja na zbiorze testowym\n",
    "test_predictions = model.predict(test_features)\n",
    "test_predictions = np.argmax(test_predictions, axis = 1)\n",
    "test_true = np.argmax(test_target, axis = 1)\n",
    "\n",
    "# Obliczanie macierzy pomyłek\n",
    "cm = confusion_matrix(test_true, test_predictions)\n",
    "TP = cm[1, 1]  # True Positives\n",
    "TN = cm[0, 0]  # True Negatives\n",
    "FP = cm[0, 1]  # False Positives\n",
    "FN = cm[1, 0]  # False Negatives\n",
    "\n",
    "print(TP)\n",
    "print(TN)\n",
    "print(FP)\n",
    "print(FN)\n",
    "\n",
    "# TPR, FPR, TNR, PPV, NPV\n",
    "ACC = (TP + TN) / (TP + TN + FP + FN)\n",
    "TPR = TP / (TP + FN)\n",
    "FPR = FP / (FP + TN)\n",
    "TNR = TN / (TN + FP)\n",
    "PPV = TP / (TP + FP)\n",
    "NPV = TN / (TN + FN)\n",
    "\n",
    "print('Accuracy (ACC):', ACC)\n",
    "print('True Positive Rate (TPR):', TPR)\n",
    "print('False Positive Rate (FPR):', FPR)\n",
    "print('True Negative Rate (TNR):', TNR)\n",
    "print('Positive Predictive Value (PPV):', PPV)\n",
    "print('Negative Predictive Value (NPV):', NPV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b9fb8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "##################################################\n",
    "##################################################\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34cc3eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "##################################################\n",
    "# WERSJA BARDZIEJ SKOMPLIKOWANA\n",
    "##################################################\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fbf1afe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-06 11:39:20,627] A new study created in memory with name: no-name-a157f879-9aa4-4477-a197-b503544d7e0b\n",
      "C:\\Users\\48798\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\48798\\AppData\\Local\\Temp\\ipykernel_12852\\3357861014.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-06 11:39:26,716] Trial 0 finished with value: 0.5642856955528259 and parameters: {'n_layers': 2, 'n_units_first': 65, 'dropout_first': 0.15017742990782984, 'n_units_0': 273, 'dropout_0': 0.4853181076610907, 'n_units_1': 159, 'dropout_1': 0.0210376745838744, 'lr': 4.298872230855751e-05}. Best is trial 0 with value: 0.5642856955528259.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-06 11:39:37,120] Trial 1 finished with value: 0.4214285612106323 and parameters: {'n_layers': 3, 'n_units_first': 293, 'dropout_first': 0.09780780586806154, 'n_units_0': 35, 'dropout_0': 0.12979165481128258, 'n_units_1': 174, 'dropout_1': 0.10254261655494107, 'n_units_2': 169, 'dropout_2': 0.369882219175659, 'lr': 0.0009151530986408943}. Best is trial 0 with value: 0.5642856955528259.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-06 11:39:42,521] Trial 2 finished with value: 0.3857142925262451 and parameters: {'n_layers': 1, 'n_units_first': 88, 'dropout_first': 0.33588355473244963, 'n_units_0': 187, 'dropout_0': 0.3577733273930603, 'lr': 0.004853532025158764}. Best is trial 0 with value: 0.5642856955528259.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 50.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-06 11:39:52,797] Trial 3 finished with value: 0.5714285969734192 and parameters: {'n_layers': 1, 'n_units_first': 53, 'dropout_first': 0.4210345943434315, 'n_units_0': 160, 'dropout_0': 0.35993295817779347, 'lr': 1.0824997565461312e-05}. Best is trial 3 with value: 0.5714285969734192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-06 11:40:02,679] Trial 4 finished with value: 0.4214285612106323 and parameters: {'n_layers': 2, 'n_units_first': 136, 'dropout_first': 0.05487553066217632, 'n_units_0': 173, 'dropout_0': 0.22989255695038785, 'n_units_1': 76, 'dropout_1': 0.21107606429877018, 'lr': 0.03886955295697219}. Best is trial 3 with value: 0.5714285969734192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 45.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-06 11:40:15,380] Trial 5 finished with value: 0.4214285612106323 and parameters: {'n_layers': 3, 'n_units_first': 179, 'dropout_first': 0.07211536689397746, 'n_units_0': 99, 'dropout_0': 0.2554740929140196, 'n_units_1': 130, 'dropout_1': 0.08088381552604601, 'n_units_2': 180, 'dropout_2': 0.44933872773196065, 'lr': 0.0006697200506576821}. Best is trial 3 with value: 0.5714285969734192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 48.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-06 11:40:26,885] Trial 6 finished with value: 0.5785714387893677 and parameters: {'n_layers': 2, 'n_units_first': 205, 'dropout_first': 0.15683790552674343, 'n_units_0': 85, 'dropout_0': 0.20368633884296028, 'n_units_1': 213, 'dropout_1': 0.1685375521867219, 'lr': 0.0001338444154247464}. Best is trial 6 with value: 0.5785714387893677.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 45.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-06 11:40:38,075] Trial 7 finished with value: 0.5428571701049805 and parameters: {'n_layers': 1, 'n_units_first': 262, 'dropout_first': 0.11663562134766547, 'n_units_0': 246, 'dropout_0': 0.4038255405108874, 'lr': 0.0007506657054910049}. Best is trial 6 with value: 0.5785714387893677.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-06 11:40:43,737] Trial 8 finished with value: 0.4214285612106323 and parameters: {'n_layers': 2, 'n_units_first': 56, 'dropout_first': 0.2872246723979933, 'n_units_0': 255, 'dropout_0': 0.09516400431096367, 'n_units_1': 115, 'dropout_1': 0.23206946227837205, 'lr': 0.04377974075253523}. Best is trial 6 with value: 0.5785714387893677.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 50.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-06 11:40:55,574] Trial 9 finished with value: 0.4642857015132904 and parameters: {'n_layers': 2, 'n_units_first': 200, 'dropout_first': 0.33208062022810814, 'n_units_0': 186, 'dropout_0': 0.15497705458309669, 'n_units_1': 131, 'dropout_1': 0.28826097609354867, 'lr': 0.0013864271659201476}. Best is trial 6 with value: 0.5785714387893677.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepsze parametry: {'n_layers': 2, 'n_units_first': 205, 'dropout_first': 0.15683790552674343, 'n_units_0': 85, 'dropout_0': 0.20368633884296028, 'n_units_1': 213, 'dropout_1': 0.1685375521867219, 'lr': 0.0001338444154247464}\n"
     ]
    }
   ],
   "source": [
    "# Korzystamy z biblioteki OPTUNA, która służy do automatycznego dostrajania hiperparametrów\n",
    "def create_model(trial):\n",
    "    # Liczba warstw ukrytych, od 1 do 3\n",
    "    n_layers = trial.suggest_int('n_layers', 1, 3)\n",
    "    model = Sequential()\n",
    "    # Dodanie pierwszej warstwy ukrytej\n",
    "    model.add(Dense(trial.suggest_int('n_units_first', 10, 300), activation = 'relu', input_shape = (train_features.shape[1],)))\n",
    "    # Dodanie warstwy Dropout\n",
    "    model.add(Dropout(trial.suggest_float('dropout_first', 0.0, 0.5)))\n",
    "\n",
    "    # Dodawanie kolejnych warstw ukrytych w pętli zależnie od liczby warstw\n",
    "    for i in range(n_layers):\n",
    "        model.add(Dense(trial.suggest_int(f'n_units_{i}', 10, 300), activation = 'relu'))\n",
    "        model.add(Dropout(trial.suggest_float(f'dropout_{i}', 0.0, 0.5)))\n",
    "\n",
    "    # Dodanie warstwy wyjściowej\n",
    "    model.add(Dense(2, activation = 'softmax'))\n",
    "    # Sugestia Optuna dotycząca współczynnika uczenia dla optymalizatora Adama\n",
    "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
    "    model.compile(optimizer = Adam(learning_rate = lr), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Definicja funkcji celu dla procesu dostrajania Optuna\n",
    "def objective(trial):\n",
    "    # Tworzenie modelu z bieżącymi parametrami sugerowanymi przez Optuna\n",
    "    model = create_model(trial)\n",
    "    # Ustawienie mechanizmu wczesnego zatrzymywania treningu w celu uniknięcia przeuczenia\n",
    "    early_stopping = EarlyStopping(monitor = 'val_loss', patience = 10, verbose = 1, restore_best_weights = True)\n",
    "    model.fit(train_features, train_target, epochs = 50, batch_size = 32, validation_split = 0.2, \n",
    "              callbacks = [early_stopping], verbose = 0)\n",
    "    _, accuracy = model.evaluate(test_features, test_target, verbose = 0)\n",
    "    return accuracy\n",
    "\n",
    "# Uruchomienie procesu dostrajania\n",
    "study = optuna.create_study(direction = 'maximize')\n",
    "study.optimize(objective, n_trials = 10)\n",
    "\n",
    "# Wyświetlenie najlepszych parametrów znalezionych przez Optuna\n",
    "print('Najlepsze parametry:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e2cc89e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.5092 - loss: 883119744.0000 - val_accuracy: 0.4286 - val_loss: 231609936.0000\n",
      "Epoch 2/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4867 - loss: 626515648.0000 - val_accuracy: 0.5268 - val_loss: 208329808.0000\n",
      "Epoch 3/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5144 - loss: 425164960.0000 - val_accuracy: 0.4732 - val_loss: 227130160.0000\n",
      "Epoch 4/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5053 - loss: 340051776.0000 - val_accuracy: 0.5625 - val_loss: 253730848.0000\n",
      "Epoch 5/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5417 - loss: 238019632.0000 - val_accuracy: 0.4464 - val_loss: 151300160.0000\n",
      "Epoch 6/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4997 - loss: 241980000.0000 - val_accuracy: 0.4554 - val_loss: 136961248.0000\n",
      "Epoch 7/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5192 - loss: 184129808.0000 - val_accuracy: 0.5536 - val_loss: 132027968.0000\n",
      "Epoch 8/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5064 - loss: 162880000.0000 - val_accuracy: 0.4464 - val_loss: 101982224.0000\n",
      "Epoch 9/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5375 - loss: 119530744.0000 - val_accuracy: 0.4554 - val_loss: 77198104.0000\n",
      "Epoch 10/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5496 - loss: 78001928.0000 - val_accuracy: 0.4196 - val_loss: 72974296.0000\n",
      "Epoch 11/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4904 - loss: 120571456.0000 - val_accuracy: 0.5000 - val_loss: 62909448.0000\n",
      "Epoch 12/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5654 - loss: 75745728.0000 - val_accuracy: 0.5179 - val_loss: 57142272.0000\n",
      "Epoch 13/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5373 - loss: 76420584.0000 - val_accuracy: 0.5089 - val_loss: 50170260.0000\n",
      "Epoch 14/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5312 - loss: 75189216.0000 - val_accuracy: 0.5357 - val_loss: 43439060.0000\n",
      "Epoch 15/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4995 - loss: 66991320.0000 - val_accuracy: 0.4464 - val_loss: 42923160.0000\n",
      "Epoch 16/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5046 - loss: 64367680.0000 - val_accuracy: 0.4911 - val_loss: 31554308.0000\n",
      "Epoch 17/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5500 - loss: 46398656.0000 - val_accuracy: 0.4643 - val_loss: 32703364.0000\n",
      "Epoch 18/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5189 - loss: 60934448.0000 - val_accuracy: 0.5000 - val_loss: 28055332.0000\n",
      "Epoch 19/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5439 - loss: 45867112.0000 - val_accuracy: 0.5179 - val_loss: 23061230.0000\n",
      "Epoch 20/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4997 - loss: 56084992.0000 - val_accuracy: 0.5089 - val_loss: 24522252.0000\n",
      "Epoch 21/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5063 - loss: 41471632.0000 - val_accuracy: 0.5357 - val_loss: 20261872.0000\n",
      "Epoch 22/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5071 - loss: 35947136.0000 - val_accuracy: 0.5000 - val_loss: 20280784.0000\n",
      "Epoch 23/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5545 - loss: 37055240.0000 - val_accuracy: 0.4643 - val_loss: 19410122.0000\n",
      "Epoch 24/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4877 - loss: 39747736.0000 - val_accuracy: 0.4732 - val_loss: 18782282.0000\n",
      "Epoch 25/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5057 - loss: 36419524.0000 - val_accuracy: 0.4643 - val_loss: 15544658.0000\n",
      "Epoch 26/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5159 - loss: 33240872.0000 - val_accuracy: 0.4375 - val_loss: 13469082.0000\n",
      "Epoch 27/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5526 - loss: 32796070.0000 - val_accuracy: 0.5000 - val_loss: 11223963.0000\n",
      "Epoch 28/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4791 - loss: 32424436.0000 - val_accuracy: 0.5179 - val_loss: 8915127.0000\n",
      "Epoch 29/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5167 - loss: 30549848.0000 - val_accuracy: 0.4821 - val_loss: 7961150.5000\n",
      "Epoch 30/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5097 - loss: 26543952.0000 - val_accuracy: 0.5000 - val_loss: 5332188.5000\n",
      "Epoch 31/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5371 - loss: 19353854.0000 - val_accuracy: 0.5179 - val_loss: 4105651.5000\n",
      "Epoch 32/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5076 - loss: 16827644.0000 - val_accuracy: 0.4821 - val_loss: 3672188.2500\n",
      "Epoch 33/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6041 - loss: 13511888.0000 - val_accuracy: 0.4911 - val_loss: 3500246.7500\n",
      "Epoch 34/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4920 - loss: 18605560.0000 - val_accuracy: 0.4196 - val_loss: 3155799.2500\n",
      "Epoch 35/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4755 - loss: 17859178.0000 - val_accuracy: 0.4464 - val_loss: 3080250.7500\n",
      "Epoch 36/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5180 - loss: 13574679.0000 - val_accuracy: 0.4732 - val_loss: 2119591.0000\n",
      "Epoch 37/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5121 - loss: 17008498.0000 - val_accuracy: 0.4464 - val_loss: 1598453.6250\n",
      "Epoch 38/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5181 - loss: 11314247.0000 - val_accuracy: 0.4821 - val_loss: 1287119.6250\n",
      "Epoch 39/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4864 - loss: 13233973.0000 - val_accuracy: 0.4821 - val_loss: 943717.5000\n",
      "Epoch 40/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5182 - loss: 13530290.0000 - val_accuracy: 0.4554 - val_loss: 560746.5625\n",
      "Epoch 41/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4740 - loss: 10752514.0000 - val_accuracy: 0.4107 - val_loss: 870665.1250\n",
      "Epoch 42/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4725 - loss: 12780706.0000 - val_accuracy: 0.4107 - val_loss: 952359.0625\n",
      "Epoch 43/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5051 - loss: 9906031.0000 - val_accuracy: 0.4464 - val_loss: 600706.1250\n",
      "Epoch 44/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4695 - loss: 10055993.0000 - val_accuracy: 0.4286 - val_loss: 376014.9688\n",
      "Epoch 45/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4820 - loss: 10566402.0000 - val_accuracy: 0.4107 - val_loss: 318130.0938\n",
      "Epoch 46/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5196 - loss: 7271109.0000 - val_accuracy: 0.4107 - val_loss: 262459.7188\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4293 - loss: 7685654.5000 - val_accuracy: 0.4107 - val_loss: 253328.1406\n",
      "Epoch 48/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5180 - loss: 5715751.5000 - val_accuracy: 0.4018 - val_loss: 297220.4062\n",
      "Epoch 49/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4875 - loss: 6414539.0000 - val_accuracy: 0.4018 - val_loss: 351258.5938\n",
      "Epoch 50/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4915 - loss: 5168883.0000 - val_accuracy: 0.4286 - val_loss: 319880.0625\n",
      "Epoch 51/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5099 - loss: 4762104.0000 - val_accuracy: 0.4107 - val_loss: 265559.2500\n",
      "Epoch 52/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4727 - loss: 4508340.5000 - val_accuracy: 0.4196 - val_loss: 173501.2188\n",
      "Epoch 53/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5372 - loss: 4480266.5000 - val_accuracy: 0.4286 - val_loss: 150355.0312\n",
      "Epoch 54/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4828 - loss: 4012823.0000 - val_accuracy: 0.4107 - val_loss: 158348.2812\n",
      "Epoch 55/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4930 - loss: 4460277.0000 - val_accuracy: 0.4107 - val_loss: 163278.3281\n",
      "Epoch 56/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5394 - loss: 2875310.5000 - val_accuracy: 0.4107 - val_loss: 205057.2344\n",
      "Epoch 57/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4876 - loss: 4373009.0000 - val_accuracy: 0.4107 - val_loss: 134950.0156\n",
      "Epoch 58/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4696 - loss: 3308446.7500 - val_accuracy: 0.4107 - val_loss: 103469.9609\n",
      "Epoch 59/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4941 - loss: 3027637.2500 - val_accuracy: 0.4107 - val_loss: 75674.1094\n",
      "Epoch 60/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5365 - loss: 2702427.5000 - val_accuracy: 0.4107 - val_loss: 76376.4375\n",
      "Epoch 61/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5136 - loss: 1739061.8750 - val_accuracy: 0.4107 - val_loss: 69746.0938\n",
      "Epoch 62/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4571 - loss: 2218869.0000 - val_accuracy: 0.4107 - val_loss: 45023.3750\n",
      "Epoch 63/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4354 - loss: 3238207.2500 - val_accuracy: 0.4107 - val_loss: 76054.2891\n",
      "Epoch 64/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4915 - loss: 1969954.1250 - val_accuracy: 0.4107 - val_loss: 126013.3359\n",
      "Epoch 65/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4622 - loss: 3037994.5000 - val_accuracy: 0.4107 - val_loss: 136980.9062\n",
      "Epoch 66/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4603 - loss: 3071459.7500 - val_accuracy: 0.4107 - val_loss: 102414.3047\n",
      "Epoch 67/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4802 - loss: 1995968.8750 - val_accuracy: 0.4107 - val_loss: 100957.5000\n",
      "Epoch 68/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4985 - loss: 1869216.2500 - val_accuracy: 0.4107 - val_loss: 108791.9844\n",
      "Epoch 69/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5013 - loss: 2151865.5000 - val_accuracy: 0.4107 - val_loss: 56806.3516\n",
      "Epoch 70/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4646 - loss: 2327593.2500 - val_accuracy: 0.5804 - val_loss: 19110.6387\n",
      "Epoch 71/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4774 - loss: 2644598.5000 - val_accuracy: 0.5804 - val_loss: 0.6929\n",
      "Epoch 72/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5189 - loss: 2145894.7500 - val_accuracy: 0.5804 - val_loss: 0.6929\n",
      "Epoch 73/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5179 - loss: 2164323.5000 - val_accuracy: 0.5804 - val_loss: 0.6928\n",
      "Epoch 74/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5325 - loss: 2748247.7500 - val_accuracy: 0.5804 - val_loss: 0.6928\n",
      "Epoch 75/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5136 - loss: 1287839.0000 - val_accuracy: 0.5804 - val_loss: 0.6927\n",
      "Epoch 76/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5283 - loss: 2381901.7500 - val_accuracy: 0.5804 - val_loss: 0.6925\n",
      "Epoch 77/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5423 - loss: 3360578.5000 - val_accuracy: 0.5804 - val_loss: 0.6924\n",
      "Epoch 78/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5412 - loss: 884528.3125 - val_accuracy: 0.5804 - val_loss: 0.6921\n",
      "Epoch 79/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5413 - loss: 998235.7500 - val_accuracy: 0.5804 - val_loss: 0.6918\n",
      "Epoch 80/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5326 - loss: 1404493.5000 - val_accuracy: 0.5804 - val_loss: 0.6916\n",
      "Epoch 81/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5455 - loss: 1402414.1250 - val_accuracy: 0.5804 - val_loss: 0.6915\n",
      "Epoch 82/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5773 - loss: 3602951.0000 - val_accuracy: 0.5804 - val_loss: 0.6913\n",
      "Epoch 83/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5705 - loss: 2611081.2500 - val_accuracy: 0.5804 - val_loss: 0.6911\n",
      "Epoch 84/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5325 - loss: 1630370.2500 - val_accuracy: 0.5804 - val_loss: 0.6909\n",
      "Epoch 85/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5103 - loss: 1205957.3750 - val_accuracy: 0.5804 - val_loss: 0.6907\n",
      "Epoch 86/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5037 - loss: 1220342.3750 - val_accuracy: 0.5804 - val_loss: 0.6905\n",
      "Epoch 87/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5114 - loss: 1325040.6250 - val_accuracy: 0.5804 - val_loss: 0.6904\n",
      "Epoch 88/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5408 - loss: 1263405.7500 - val_accuracy: 0.5804 - val_loss: 0.6903\n",
      "Epoch 89/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5179 - loss: 1153042.6250 - val_accuracy: 0.5804 - val_loss: 0.6901\n",
      "Epoch 90/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5035 - loss: 1515131.2500 - val_accuracy: 0.5804 - val_loss: 0.6899\n",
      "Epoch 91/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5190 - loss: 1414653.7500 - val_accuracy: 0.5804 - val_loss: 0.6897\n",
      "Epoch 92/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5318 - loss: 1595895.8750 - val_accuracy: 0.5804 - val_loss: 0.6895\n",
      "Epoch 93/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5169 - loss: 937715.5000 - val_accuracy: 0.5804 - val_loss: 0.6894\n",
      "Epoch 94/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5621 - loss: 871689.0625 - val_accuracy: 0.5804 - val_loss: 0.6891\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5426 - loss: 1129692.3750 - val_accuracy: 0.5804 - val_loss: 0.6889\n",
      "Epoch 96/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5363 - loss: 1645109.1250 - val_accuracy: 0.5804 - val_loss: 0.6889\n",
      "Epoch 97/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5415 - loss: 795677.9375 - val_accuracy: 0.5804 - val_loss: 0.6887\n",
      "Epoch 98/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5156 - loss: 1379123.5000 - val_accuracy: 0.5804 - val_loss: 0.6887\n",
      "Epoch 99/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5305 - loss: 3365675.0000 - val_accuracy: 0.5804 - val_loss: 0.6886\n",
      "Epoch 100/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5405 - loss: 1115771.6250 - val_accuracy: 0.5804 - val_loss: 0.6885\n",
      "Restoring model weights from the end of the best epoch: 100.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4156 - loss: 0.6991 \n",
      "Test loss: 0.6986910104751587\n",
      "Test accuracy: 0.4214285612106323\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5282 - loss: 0.6919 \n",
      "Train loss: 0.6909676790237427\n",
      "Train accuracy: 0.5420393347740173\n"
     ]
    }
   ],
   "source": [
    "best_params = {'n_layers': 3, \n",
    "               'n_units_first': 105, \n",
    "               'dropout_first': 0.1498309254789278, \n",
    "               'n_units_0': 78, \n",
    "               'dropout_0': 0.33462120080999536, \n",
    "               'n_units_1': 147, \n",
    "               'dropout_1': 0.43624463704269206, \n",
    "               'n_units_2': 126, \n",
    "               'dropout_2': 0.42630200041120037, \n",
    "               'lr': 0.00041889174933029466}\n",
    "\n",
    "# Budujemy model sieci neuronowej\n",
    "model = Sequential()\n",
    "model.add(Dense(best_params['n_units_first'], activation = 'relu', input_shape = (train_features.shape[1],)))\n",
    "model.add(Dropout(best_params['dropout_first']))\n",
    "\n",
    "model.add(Dense(best_params['n_units_0'], activation = 'relu'))\n",
    "model.add(Dropout(best_params['dropout_0']))\n",
    "\n",
    "model.add(Dense(best_params['n_units_1'], activation = 'relu'))\n",
    "model.add(Dropout(best_params['dropout_1']))\n",
    "\n",
    "model.add(Dense(best_params['n_units_2'], activation = 'relu'))\n",
    "model.add(Dropout(best_params['dropout_2']))\n",
    "\n",
    "model.add(Dense(2, activation = 'softmax'))\n",
    "\n",
    "# Optymalizator Adam\n",
    "optimizer = Adam(learning_rate = best_params['lr'])\n",
    "\n",
    "model.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Dodajemy funkcję, która przerwie trenowanie modelu, gdy model przestaje poprawiać swoją wydajność na zbiorze walidacyjnym\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss',  \n",
    "                               patience = 10,         # liczba epok bez poprawy po której trening zostanie zatrzymany\n",
    "                               verbose = 1,           \n",
    "                               restore_best_weights = True) \n",
    "\n",
    "\n",
    "# Trenowanie modelu z dodaniem callbacku\n",
    "history = model.fit(train_features, train_target, \n",
    "                    epochs = 100, \n",
    "                    batch_size = 32, \n",
    "                    validation_split = 0.2,\n",
    "                    callbacks = [early_stopping]) \n",
    "\n",
    "# Ocena modelu na danych testowych\n",
    "test_performance = model.evaluate(test_features, test_target)\n",
    "print('Test loss:', test_performance[0])\n",
    "print('Test accuracy:', test_performance[1])\n",
    "\n",
    "# Ocena modelu na danych treningowych\n",
    "train_performance = model.evaluate(train_features, train_target)\n",
    "print('Train loss:', train_performance[0])\n",
    "print('Train accuracy:', train_performance[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bce4c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "303\n",
      "0\n",
      "256\n",
      "0\n",
      "Accuracy (ACC): 0.5420393559928444\n",
      "True Positive Rate (TPR): 1.0\n",
      "False Positive Rate (FPR): 1.0\n",
      "True Negative Rate (TNR): 0.0\n",
      "Positive Predictive Value (PPV): 0.5420393559928444\n",
      "Negative Predictive Value (NPV): nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\48798\\AppData\\Local\\Temp\\ipykernel_12852\\1020962155.py:24: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  NPV = TN / (TN + FN)\n"
     ]
    }
   ],
   "source": [
    "# Predykcja na zbiorze treningowym\n",
    "train_predictions = model.predict(train_features)\n",
    "train_predictions = np.argmax(train_predictions, axis = 1)\n",
    "train_true = np.argmax(train_target, axis = 1)\n",
    "\n",
    "# Obliczanie macierzy pomyłek\n",
    "cm = confusion_matrix(train_true, train_predictions)\n",
    "TP = cm[1, 1]  # True Positives\n",
    "TN = cm[0, 0]  # True Negatives\n",
    "FP = cm[0, 1]  # False Positives\n",
    "FN = cm[1, 0]  # False Negatives\n",
    "\n",
    "print(TP)\n",
    "print(TN)\n",
    "print(FP)\n",
    "print(FN)\n",
    "\n",
    "# TPR, FPR, TNR, PPV, NPV\n",
    "ACC = (TP + TN) / (TP + TN + FP + FN)\n",
    "TPR = TP / (TP + FN)\n",
    "FPR = FP / (FP + TN)\n",
    "TNR = TN / (TN + FP)\n",
    "PPV = TP / (TP + FP)\n",
    "NPV = TN / (TN + FN)\n",
    "\n",
    "print('Accuracy (ACC):', ACC)\n",
    "print('True Positive Rate (TPR):', TPR)\n",
    "print('False Positive Rate (FPR):', FPR)\n",
    "print('True Negative Rate (TNR):', TNR)\n",
    "print('Positive Predictive Value (PPV):', PPV)\n",
    "print('Negative Predictive Value (NPV):', NPV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e441350",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "59\n",
      "0\n",
      "81\n",
      "0\n",
      "Accuracy (ACC): 0.42142857142857143\n",
      "True Positive Rate (TPR): 1.0\n",
      "False Positive Rate (FPR): 1.0\n",
      "True Negative Rate (TNR): 0.0\n",
      "Positive Predictive Value (PPV): 0.42142857142857143\n",
      "Negative Predictive Value (NPV): nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\48798\\AppData\\Local\\Temp\\ipykernel_12852\\4228670605.py:24: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  NPV = TN / (TN + FN)\n"
     ]
    }
   ],
   "source": [
    "# Predykcja na zbiorze testowym\n",
    "test_predictions = model.predict(test_features)\n",
    "test_predictions = np.argmax(test_predictions, axis = 1)\n",
    "test_true = np.argmax(test_target, axis = 1)\n",
    "\n",
    "# Obliczanie macierzy pomyłek\n",
    "cm = confusion_matrix(test_true, test_predictions)\n",
    "TP = cm[1, 1]  # True Positives\n",
    "TN = cm[0, 0]  # True Negatives\n",
    "FP = cm[0, 1]  # False Positives\n",
    "FN = cm[1, 0]  # False Negatives\n",
    "\n",
    "print(TP)\n",
    "print(TN)\n",
    "print(FP)\n",
    "print(FN)\n",
    "\n",
    "# TPR, FPR, TNR, PPV, NPV\n",
    "ACC = (TP + TN) / (TP + TN + FP + FN)\n",
    "TPR = TP / (TP + FN)\n",
    "FPR = FP / (FP + TN)\n",
    "TNR = TN / (TN + FP)\n",
    "PPV = TP / (TP + FP)\n",
    "NPV = TN / (TN + FN)\n",
    "\n",
    "print('Accuracy (ACC):', ACC)\n",
    "print('True Positive Rate (TPR):', TPR)\n",
    "print('False Positive Rate (FPR):', FPR)\n",
    "print('True Negative Rate (TNR):', TNR)\n",
    "print('Positive Predictive Value (PPV):', PPV)\n",
    "print('Negative Predictive Value (NPV):', NPV)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
