{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e245b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense, Dropout\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "745310cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import optuna\n",
    "import yfinance as yf\n",
    "import pandas_datareader.data as web\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas_ta as ta\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Nadam\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.utils import plot_model\n",
    "from keras.layers import Dropout, Dense, GRU, LSTM, Flatten\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecfe67dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category = pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bdd371a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "676\n",
      "(676, 127)\n"
     ]
    }
   ],
   "source": [
    "# Pobieramy dane dotyczące BTC z yahoo\n",
    "BTC = yf.download('BTC-USD', start = '2022-02-24', end = '2024-01-01')\n",
    "\n",
    "BTC['Target'] = (BTC['Close'].diff() > 0).astype(int)\n",
    "\n",
    "def add_lagged_features(data, column_name, n_days):\n",
    "    for i in range(1, n_days + 1):\n",
    "        lagged_column_name = f'{column_name}_{i}d_back'\n",
    "        data[lagged_column_name] = data[column_name].shift(i)\n",
    "    return data\n",
    "\n",
    "BTC = add_lagged_features(BTC, 'Close', 30)\n",
    "BTC = add_lagged_features(BTC, 'Open', 30)\n",
    "BTC = add_lagged_features(BTC, 'High', 30)\n",
    "BTC = add_lagged_features(BTC, 'Low', 30)\n",
    "\n",
    "# df = pd.DataFrame()\n",
    "# df = BTC.copy()\n",
    "# print(BTC.head())\n",
    "print(len(BTC))\n",
    "print(BTC.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bea0121c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BTC = BTC.drop('Adj Close', axis=1)\n",
    "BTC = BTC.dropna().reset_index(drop = True)\n",
    "# BTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "148e7526",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame()\n",
    "dataset = BTC[['Open', 'High', 'Low', 'Close', 'Volume', 'Target']].copy()\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4639688",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_in = 20\n",
    "output_features = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c36088bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_value = pd.DataFrame(dataset.iloc[:, :])\n",
    "X_value = X_value.drop('Target', axis='columns')\n",
    "# X_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9eb64e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_value = pd.DataFrame(dataset.Target)\n",
    "y_value = to_categorical(y_value)\n",
    "# y_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3d27bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler.fit(X_value)\n",
    "X_value = scaler.fit_transform(X_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b089df56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y(X_data, y_data):\n",
    "    X = list()\n",
    "    y = list()\n",
    "\n",
    "    length = len(X_data)\n",
    "    for i in range(0, length-n_steps_in, 1):\n",
    "        X_value = X_data[i: i + n_steps_in][:, :]\n",
    "        # y_value = y_data[i + n_steps_in: i + (n_steps_in + n_steps_out)][:, :]\n",
    "        y_value = y_data[i + n_steps_in]\n",
    "        if len(X_value) == n_steps_in and len(y_value) == output_features:\n",
    "            X.append(X_value)\n",
    "            y.append(y_value)\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "421d0771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(data):\n",
    "    train_size = int(0.8 * len(X))\n",
    "    data_train = data[0:train_size]\n",
    "    data_test = data[train_size:]\n",
    "    return data_train, data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d239ce9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (626, 20, 5)\n",
      "y shape:  (626, 2)\n",
      "Train features shape:  (500, 20, 5)\n",
      "Test features shape:  (126, 20, 5)\n",
      "Train features shape:  (500, 2)\n",
      "Test features shape:  (126, 2)\n"
     ]
    }
   ],
   "source": [
    "X, y = get_X_y(X_value, y_value)\n",
    "print('X shape: ', X.shape)\n",
    "print('y shape: ', y.shape)\n",
    "train_features, test_features = split_train_test(X) \n",
    "train_target, test_target = split_train_test(y) \n",
    "\n",
    "print('Train features shape: ', train_features.shape)\n",
    "print('Test features shape: ', test_features.shape)\n",
    "print('Train features shape: ', train_target.shape)\n",
    "print('Test features shape: ', test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2450a260",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = train_features.shape[1]\n",
    "input_feature_size = train_features.shape[2]\n",
    "output_dim = train_target.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f4fece6",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCH = 50\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "def basic_simpleRNN(input_dim, output_dim, input_feature_size):\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(units=63, return_sequences=True, activation='relu', input_shape=(input_dim, input_feature_size)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(SimpleRNN(250, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(train_features, train_target, epochs = N_EPOCH, \n",
    "                        validation_data = (test_features, test_target),\n",
    "                        batch_size = BATCH_SIZE, verbose = 2, shuffle = False)\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b79d271",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\48798\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 - 19s - 2s/step - accuracy: 0.4660 - loss: 0.7659 - val_accuracy: 0.4762 - val_loss: 0.7397\n",
      "Epoch 2/50\n",
      "8/8 - 1s - 86ms/step - accuracy: 0.5560 - loss: 0.7006 - val_accuracy: 0.4444 - val_loss: 0.7040\n",
      "Epoch 3/50\n",
      "8/8 - 1s - 169ms/step - accuracy: 0.5200 - loss: 0.7296 - val_accuracy: 0.4444 - val_loss: 0.7242\n",
      "Epoch 4/50\n",
      "8/8 - 1s - 72ms/step - accuracy: 0.5240 - loss: 0.7162 - val_accuracy: 0.4841 - val_loss: 0.7107\n",
      "Epoch 5/50\n",
      "8/8 - 1s - 76ms/step - accuracy: 0.5560 - loss: 0.7056 - val_accuracy: 0.4603 - val_loss: 0.7579\n",
      "Epoch 6/50\n",
      "8/8 - 1s - 76ms/step - accuracy: 0.5620 - loss: 0.7105 - val_accuracy: 0.4762 - val_loss: 0.7539\n",
      "Epoch 7/50\n",
      "8/8 - 1s - 84ms/step - accuracy: 0.5180 - loss: 0.7742 - val_accuracy: 0.4603 - val_loss: 0.7103\n",
      "Epoch 8/50\n",
      "8/8 - 1s - 75ms/step - accuracy: 0.5440 - loss: 0.6991 - val_accuracy: 0.4683 - val_loss: 0.7364\n",
      "Epoch 9/50\n",
      "8/8 - 1s - 106ms/step - accuracy: 0.5100 - loss: 0.7204 - val_accuracy: 0.4365 - val_loss: 0.7187\n",
      "Epoch 10/50\n",
      "8/8 - 1s - 71ms/step - accuracy: 0.5760 - loss: 0.6985 - val_accuracy: 0.4841 - val_loss: 0.7223\n",
      "Epoch 11/50\n",
      "8/8 - 1s - 81ms/step - accuracy: 0.5400 - loss: 0.7163 - val_accuracy: 0.4762 - val_loss: 0.7361\n",
      "Epoch 12/50\n",
      "8/8 - 1s - 100ms/step - accuracy: 0.5380 - loss: 0.6932 - val_accuracy: 0.4365 - val_loss: 0.7450\n",
      "Epoch 13/50\n",
      "8/8 - 1s - 122ms/step - accuracy: 0.5920 - loss: 0.6840 - val_accuracy: 0.4762 - val_loss: 0.7360\n",
      "Epoch 14/50\n",
      "8/8 - 1s - 112ms/step - accuracy: 0.5540 - loss: 0.6851 - val_accuracy: 0.4365 - val_loss: 0.7268\n",
      "Epoch 15/50\n",
      "8/8 - 1s - 108ms/step - accuracy: 0.5320 - loss: 0.7154 - val_accuracy: 0.4524 - val_loss: 0.7346\n",
      "Epoch 16/50\n",
      "8/8 - 1s - 95ms/step - accuracy: 0.5000 - loss: 0.7282 - val_accuracy: 0.4444 - val_loss: 0.7429\n",
      "Epoch 17/50\n",
      "8/8 - 1s - 120ms/step - accuracy: 0.5420 - loss: 0.6923 - val_accuracy: 0.4683 - val_loss: 0.7408\n",
      "Epoch 18/50\n",
      "8/8 - 1s - 135ms/step - accuracy: 0.5400 - loss: 0.7133 - val_accuracy: 0.4683 - val_loss: 0.7513\n",
      "Epoch 19/50\n",
      "8/8 - 1s - 100ms/step - accuracy: 0.5300 - loss: 0.7111 - val_accuracy: 0.4683 - val_loss: 0.7698\n",
      "Epoch 20/50\n",
      "8/8 - 1s - 129ms/step - accuracy: 0.5420 - loss: 0.6810 - val_accuracy: 0.4762 - val_loss: 0.7040\n",
      "Epoch 21/50\n",
      "8/8 - 1s - 90ms/step - accuracy: 0.5680 - loss: 0.6752 - val_accuracy: 0.4524 - val_loss: 0.7675\n",
      "Epoch 22/50\n",
      "8/8 - 1s - 88ms/step - accuracy: 0.5500 - loss: 0.6881 - val_accuracy: 0.5000 - val_loss: 0.7153\n",
      "Epoch 23/50\n",
      "8/8 - 1s - 112ms/step - accuracy: 0.6280 - loss: 0.6643 - val_accuracy: 0.4524 - val_loss: 0.7780\n",
      "Epoch 24/50\n",
      "8/8 - 1s - 90ms/step - accuracy: 0.5460 - loss: 0.6936 - val_accuracy: 0.4683 - val_loss: 0.7879\n",
      "Epoch 25/50\n",
      "8/8 - 1s - 91ms/step - accuracy: 0.5440 - loss: 0.6836 - val_accuracy: 0.4444 - val_loss: 0.7148\n",
      "Epoch 26/50\n",
      "8/8 - 1s - 93ms/step - accuracy: 0.5960 - loss: 0.6707 - val_accuracy: 0.4603 - val_loss: 0.7656\n",
      "Epoch 27/50\n",
      "8/8 - 1s - 107ms/step - accuracy: 0.6100 - loss: 0.6539 - val_accuracy: 0.4921 - val_loss: 0.7424\n",
      "Epoch 28/50\n",
      "8/8 - 1s - 94ms/step - accuracy: 0.6220 - loss: 0.6468 - val_accuracy: 0.4444 - val_loss: 0.7863\n",
      "Epoch 29/50\n",
      "8/8 - 1s - 165ms/step - accuracy: 0.5860 - loss: 0.6813 - val_accuracy: 0.4841 - val_loss: 0.7545\n",
      "Epoch 30/50\n",
      "8/8 - 1s - 131ms/step - accuracy: 0.5340 - loss: 0.7052 - val_accuracy: 0.4683 - val_loss: 0.7563\n",
      "Epoch 31/50\n",
      "8/8 - 1s - 82ms/step - accuracy: 0.5620 - loss: 0.6749 - val_accuracy: 0.5317 - val_loss: 0.7393\n",
      "Epoch 32/50\n",
      "8/8 - 1s - 71ms/step - accuracy: 0.5760 - loss: 0.6689 - val_accuracy: 0.5079 - val_loss: 0.7642\n",
      "Epoch 33/50\n",
      "8/8 - 1s - 91ms/step - accuracy: 0.6040 - loss: 0.6559 - val_accuracy: 0.5000 - val_loss: 0.7658\n",
      "Epoch 34/50\n",
      "8/8 - 1s - 75ms/step - accuracy: 0.6040 - loss: 0.6536 - val_accuracy: 0.4683 - val_loss: 0.7688\n",
      "Epoch 35/50\n",
      "8/8 - 1s - 79ms/step - accuracy: 0.6080 - loss: 0.6494 - val_accuracy: 0.5317 - val_loss: 0.7333\n",
      "Epoch 36/50\n",
      "8/8 - 1s - 103ms/step - accuracy: 0.6500 - loss: 0.6387 - val_accuracy: 0.5238 - val_loss: 0.7865\n",
      "Epoch 37/50\n",
      "8/8 - 1s - 159ms/step - accuracy: 0.6340 - loss: 0.6293 - val_accuracy: 0.4683 - val_loss: 0.8160\n",
      "Epoch 38/50\n",
      "8/8 - 1s - 116ms/step - accuracy: 0.6200 - loss: 0.6448 - val_accuracy: 0.5000 - val_loss: 0.7869\n",
      "Epoch 39/50\n",
      "8/8 - 1s - 72ms/step - accuracy: 0.6220 - loss: 0.6413 - val_accuracy: 0.5317 - val_loss: 0.7561\n",
      "Epoch 40/50\n",
      "8/8 - 1s - 88ms/step - accuracy: 0.5840 - loss: 0.6726 - val_accuracy: 0.4841 - val_loss: 0.7611\n",
      "Epoch 41/50\n",
      "8/8 - 1s - 94ms/step - accuracy: 0.6120 - loss: 0.6406 - val_accuracy: 0.4762 - val_loss: 0.7837\n",
      "Epoch 42/50\n",
      "8/8 - 1s - 85ms/step - accuracy: 0.6060 - loss: 0.6376 - val_accuracy: 0.4603 - val_loss: 0.8273\n",
      "Epoch 43/50\n",
      "8/8 - 1s - 90ms/step - accuracy: 0.6120 - loss: 0.6430 - val_accuracy: 0.5000 - val_loss: 0.7704\n",
      "Epoch 44/50\n",
      "8/8 - 1s - 79ms/step - accuracy: 0.6500 - loss: 0.6029 - val_accuracy: 0.5079 - val_loss: 0.7937\n",
      "Epoch 45/50\n",
      "8/8 - 1s - 74ms/step - accuracy: 0.6680 - loss: 0.6065 - val_accuracy: 0.4762 - val_loss: 0.8321\n",
      "Epoch 46/50\n",
      "8/8 - 1s - 86ms/step - accuracy: 0.6780 - loss: 0.5885 - val_accuracy: 0.5000 - val_loss: 0.7517\n",
      "Epoch 47/50\n",
      "8/8 - 1s - 78ms/step - accuracy: 0.6460 - loss: 0.6020 - val_accuracy: 0.4921 - val_loss: 0.8637\n",
      "Epoch 48/50\n",
      "8/8 - 1s - 84ms/step - accuracy: 0.6360 - loss: 0.6036 - val_accuracy: 0.5238 - val_loss: 0.8045\n",
      "Epoch 49/50\n",
      "8/8 - 1s - 166ms/step - accuracy: 0.6600 - loss: 0.5928 - val_accuracy: 0.5476 - val_loss: 0.7857\n",
      "Epoch 50/50\n",
      "8/8 - 1s - 100ms/step - accuracy: 0.6440 - loss: 0.6287 - val_accuracy: 0.5476 - val_loss: 0.8322\n"
     ]
    }
   ],
   "source": [
    "model, history = basic_simpleRNN(input_dim, output_dim, input_feature_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65419d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7315 - loss: 0.5147\n",
      "Train loss: 0.5849469900131226\n",
      "Train accuracy: 0.6660000085830688\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5315 - loss: 0.7772\n",
      "Test loss: 0.8321601152420044\n",
      "Test accuracy: 0.5476190447807312\n"
     ]
    }
   ],
   "source": [
    "# Ocena modelu na danych treningowych\n",
    "train_performance = model.evaluate(train_features, train_target)\n",
    "print('Train loss:', train_performance[0])\n",
    "print('Train accuracy:', train_performance[1])\n",
    "\n",
    "test_performance = model.evaluate(test_features, test_target)\n",
    "print('Test loss:', test_performance[0])\n",
    "print('Test accuracy:', test_performance[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bce4c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 129ms/step\n",
      "96\n",
      "237\n",
      "31\n",
      "136\n",
      "Accuracy (ACC): 0.666\n",
      "True Positive Rate (TPR): 0.41379310344827586\n",
      "False Positive Rate (FPR): 0.11567164179104478\n",
      "True Negative Rate (TNR): 0.8843283582089553\n",
      "Positive Predictive Value (PPV): 0.7559055118110236\n",
      "Negative Predictive Value (NPV): 0.6353887399463807\n"
     ]
    }
   ],
   "source": [
    "# Predykcja na zbiorze treningowym\n",
    "train_predictions = model.predict(train_features)\n",
    "train_predictions = np.argmax(train_predictions, axis = 1)\n",
    "train_true = np.argmax(train_target, axis = 1)\n",
    "\n",
    "# Obliczanie macierzy pomyłek\n",
    "cm = confusion_matrix(train_true, train_predictions)\n",
    "TP = cm[1, 1]  # True Positives\n",
    "TN = cm[0, 0]  # True Negatives\n",
    "FP = cm[0, 1]  # False Positives\n",
    "FN = cm[1, 0]  # False Negatives\n",
    "\n",
    "print(TP)\n",
    "print(TN)\n",
    "print(FP)\n",
    "print(FN)\n",
    "\n",
    "# TPR, FPR, TNR, PPV, NPV\n",
    "ACC = (TP + TN) / (TP + TN + FP + FN)\n",
    "TPR = TP / (TP + FN)\n",
    "FPR = FP / (FP + TN)\n",
    "TNR = TN / (TN + FP)\n",
    "PPV = TP / (TP + FP)\n",
    "NPV = TN / (TN + FN)\n",
    "\n",
    "print('Accuracy (ACC):', ACC)\n",
    "print('True Positive Rate (TPR):', TPR)\n",
    "print('False Positive Rate (FPR):', FPR)\n",
    "print('True Negative Rate (TNR):', TNR)\n",
    "print('Positive Predictive Value (PPV):', PPV)\n",
    "print('Negative Predictive Value (NPV):', NPV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e441350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "27\n",
      "42\n",
      "17\n",
      "40\n",
      "Accuracy (ACC): 0.5476190476190477\n",
      "True Positive Rate (TPR): 0.40298507462686567\n",
      "False Positive Rate (FPR): 0.288135593220339\n",
      "True Negative Rate (TNR): 0.711864406779661\n",
      "Positive Predictive Value (PPV): 0.6136363636363636\n",
      "Negative Predictive Value (NPV): 0.5121951219512195\n"
     ]
    }
   ],
   "source": [
    "# Predykcja na zbiorze testowym\n",
    "test_predictions = model.predict(test_features)\n",
    "test_predictions = np.argmax(test_predictions, axis = 1)\n",
    "test_true = np.argmax(test_target, axis = 1)\n",
    "\n",
    "# Obliczanie macierzy pomyłek\n",
    "cm = confusion_matrix(test_true, test_predictions)\n",
    "TP = cm[1, 1]  # True Positives\n",
    "TN = cm[0, 0]  # True Negatives\n",
    "FP = cm[0, 1]  # False Positives\n",
    "FN = cm[1, 0]  # False Negatives\n",
    "\n",
    "print(TP)\n",
    "print(TN)\n",
    "print(FP)\n",
    "print(FN)\n",
    "\n",
    "# TPR, FPR, TNR, PPV, NPV\n",
    "ACC = (TP + TN) / (TP + TN + FP + FN)\n",
    "TPR = TP / (TP + FN)\n",
    "FPR = FP / (FP + TN)\n",
    "TNR = TN / (TN + FP)\n",
    "PPV = TP / (TP + FP)\n",
    "NPV = TN / (TN + FN)\n",
    "\n",
    "print('Accuracy (ACC):', ACC)\n",
    "print('True Positive Rate (TPR):', TPR)\n",
    "print('False Positive Rate (FPR):', FPR)\n",
    "print('True Negative Rate (TNR):', TNR)\n",
    "print('Positive Predictive Value (PPV):', PPV)\n",
    "print('Negative Predictive Value (NPV):', NPV)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
